% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.
\pdfminorversion=7
\pdfobjcompresslevel=3
\pdfcompresslevel=9


\documentclass[11pt]{article}

% Change "review" to "final" to generate the final (sometimes called camera-ready) version.
\usepackage{acl}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

\usepackage{amsmath}

% This is not strictly necessary, and may be commented out,
% but it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

%Including images in your LaTeX document requires adding
%additional package(s)
\usepackage{graphicx}

\title{Etude du meilleur classifieur pour le DEFT de 2009}

\author{
  \text{MANSERI Kéhina\textsuperscript{(1)(2)}}
  \text{SIRVEN-VIENOT Alix\textsuperscript{(1)(2)}}
  \text{VAN-DEN-ZANDE Débora\textsuperscript{(1)(3)}}
\\
\\
  \textsuperscript{(1)}Université Paris Nanterre
  \textsuperscript{(2)}Parcours Recherche et Développement
  \textsuperscript{(3)}Parcours Pro
\\
\\
    \small {
    manserikehina@gmail.com, alix.vienot@gmail.com, vdzdebora@gmail.com
    }
\\
}

\begin{document}
\maketitle
\begin{abstract}
Coucou bouh abstract ! On va expliquer pleins de trucs mais pour l'instant on sait pas ce qu'on fait donc no lol.

Si on veut citer le texte on peut faire comme ça \cite{forest2009variation} et je trouve ça très stylé.

\end{abstract}

\section{Introduction}
Vous pouvez retrouver notre travail sur notre GitHub\footnote{\url{https://github.com/KehinaleK/deft09/tree/main}} pour accéder à l'entièreté de notre code.

Dans cet article, nous présentons nos résultats pour la recherche 

\section{Présentation des données}

Notre objectif est d'entraîner un modèle qui détermine automatiquement le parti politique d’appartenance de chaque intervenant dans le corpus parlementaire. 

Notre corpus est multilingue, c'est-à-dire qu'il contient plusieurs ensembles dans des langues différentes telles que le français, l'anglais et l'italien. C'est donc un corpus parallèle et comparable auquel nous avons affaire. 

\subsection{Extraction des données}
Nous avons extrait les données sur le site du DEFT\footnote{\textit{https://deft.lisn.upsaclay.fr/}} en format xml et nous les avons parsé avec BeautifulSoup. 

En comparant la longueur de la liste de labels et les id des échantillons de test, nous avons pu remarquer que deux interventions ne disposaient pas de label.

Ces deux échantillons ne sont ensuite pas stockés dans la dataframe utilisée pour le reste du TP.



\subsection{Suppression des doublons}
Après concertation avec les autres étudiants, nous avons été informées qu'il y avait des doublons entre les ensembles de train et de test.

Nous avons trouvé au total 7 813 textes en communs entre les données d'entraînement et de test. Nous voulions donc retirer ces doublons des deux ensembles tout en essayant de respecter le répartition du corpus qui est de base de 60\% des échantillons pour le train et 40\% pour le test. 

En effet, retirer tous les doublons de l'ensemble de train nous donnerait un split bien trop proche.

Après avoir enlevé les doublons, nous avons obtenu un split de 53,40\% pour le train et 46,60\% pour le test. Pour avoir une distribution exacte de 60/40, nous avons retiré certains textes de l'ensemble de test.

\subsection{Distribution des classes}
\begin{table}[ht]
    \centering
    \begin{tabular}{|l|c|c|c|}
        \hline
        \textbf{Classe}   & \textbf{Train} & \textbf{Test} & \textbf{Pourcentage} \\ \hline
        \textbf{PSE}      & 3650           & 2489          & 40.54\%              \\ \hline
        \textbf{ELDR}     & 1351           & 908           & 40.19\%              \\ \hline
        \textbf{Verts-ALE}& 1609           & 1072          & 39.99\%              \\ \hline
        \textbf{PPE-DE}   & 4635           & 3047          & 39.66\%              \\ \hline
        \textbf{GUE-NGL}  & 1823           & 1196          & 39.62\%              \\ \hline
    \end{tabular}
    \caption{Distribution des pourcentages entre Train et Test.}
    \label{tab:pourcentage_test}
\end{table}

\textbf{Résumé des totaux} \\
Total Train : \> 13068 \\
Total Test  : \> 8712 \\
Pourcentage Global Test : \> 40.00\%

Nous pouvons maintenant observer la distribution des classes dans les différents splits sur la Figure~\ref{fig:graph_avant}.

\begin{figure}[h]
  \includegraphics[width=\columnwidth]{latex/graphique_avant.png}
  \caption{Répartition des classes \textbf{avant} nettoyage et rééquilibrage du split}
  \label{fig:graph_avant} % pareil pour citer Figure~\ref{fig:graph_avant}
\end{figure}



\begin{figure}[h]
  \includegraphics[width=\columnwidth]{latex/graphique_apres.png}
  \caption{Répartition des classes \textbf{après} nettoyage et rééquilibrage du split}
  \label{fig:graph_apres} % Figure~\ref{fig:graph_apres}
\end{figure}


\section{Pré-traitement des données}

\subsection{Normalisation des données}

\subsection{Vectorisation des données}

\section{Comparaison des modèles}
Nous avons décidé de tester plusieurs modèles qui ont des types de classifications différentes (cf. Tableau~\ref{tab:classifieurs_types}).

\begin{table}[h]
    \centering
    \begin{tabular}{|l|l|}
        \hline
        \textbf{Nom du Classifieur}        & \textbf{Type} \\ \hline
        LinearSVC                         & Linéaire      \\ \hline
        RandomForestClassifier            & Ensemble      \\ \hline
        KNeighborsClassifier              & Non-linéaire  \\ \hline
        PassiveAggressiveClassifier       & Linéaire      \\ \hline
        MultinomialNB                     & Probabiliste  \\ \hline
        ComplementNB                      & Probabiliste  \\ \hline
        SVC                               & Non-linéaire  \\ \hline
        RidgeClassifier                   & Linéaire      \\ \hline
        LGBMClassifier                    & Ensemble      \\ \hline
        LogisticRegression                & Linéaire      \\ \hline
        SGDClassifier                     & Linéaire      \\ \hline
    \end{tabular}
    \caption{Liste des classifieurs et leur type.}
    \label{tab:classifieurs_types} % ça c'est pour le citer après ! Tableau~\ref{tab:classifieurs_types}
\end{table}

\subsection{Choix des algorithmes}
Pour notre étude, nous avons choisi de tester un large éventail de modèles, incluant des approches linéaires, probabilistes, non-linéaires et des ensembles. Bien que nous savions qu'il était possible de concentrer nos efforts sur un seul type d'algorithme, nous avons profité du temps disponible pour explorer différents classifieurs. Cette approche nous permet non seulement de comparer les performances des algorithmes, mais aussi de valider notre hypothèse concernant l'impact des déséquilibres de classes dans nos données.

Nos données étant extrêmement déséquilibrées, nous anticipons que les modèles linéaires auront des performances limitées, car ils sont souvent moins adaptés à ce type de scénario. En revanche, les modèles probabilistes, tels que MultinomialNB et ComplementNB, sont particulièrement bien adaptés aux jeux de données déséquilibrés grâce à leur capacité à estimer directement des probabilités de classes.

Cette exploration nous permettra de retenir les trois meilleurs algorithmes à l'issue de nos tests. Ces résultats serviront également à justifier nos choix méthodologiques et à appuyer notre intuition selon laquelle les modèles probabilistes et les modèles utilisant des techniques d'ensemble (comme Random Forest ou LGBMClassifier) seront mieux adaptés aux particularités de nos données. En procédant ainsi, nous avons cherché à maximiser la robustesse de notre analyse tout en assurant une base solide pour nos conclusions.

\subsection{Organisation de la comparaison}

\section{Stratégies d'amélioriation}


\section{Évaluation des modèles}

\subsection{Métriques d'évaluation}
\begin{table}[ht]
    \centering
    \begin{tabular}{|l|c|c|c|}
        \hline
        \textbf{Algorithme} & \textbf{Précision} & \textbf{Rappel} & \textbf{F1-score} \\ \hline
        Logistic Regression & 0.85               & 0.82            & 0.83              \\ \hline
        Random Forest       & 0.88               & 0.85            & 0.86              \\ \hline
        SVM                 & 0.87               & 0.84            & 0.85              \\ \hline
    \end{tabular}
    \caption{Résultats des algorithmes sur les métriques de classification.}
    \label{tab:resultats_algo}
\end{table}

\subsection{Analyse des résultats}


\section{Conclusion}


\bibliography{custom}
\cite{forest2009variation}

\end{document}